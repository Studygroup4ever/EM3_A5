---
title: "Assignment 5 - Meta-analysis of pitch in schizophrenia"
author: "Riccardo Fusaroli"
date: "3/7/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Building on the shoulders of giants: meta-analysis
## Questions to be answered

1. What is the current evidence for distinctive vocal patterns in schizophrenia? Report how many papers report quantitative estimates, comment on what percentage of the overall studies reviewed they represent (see PRISMA chart) your method to analyze them, the estimated effect size of the difference (mean effect size and standard error) and forest plots representing it. 

N.B. Only measures of pitch mean and pitch sd are required for the assignment (all the other measures have been removed from the data-set for the sake of simplicity). 

2. Do the results match your own analysis from Assignment 3? If you add your results to the meta-analysis, do the estimated effect sizes change? Report the new estimates and the new forest plots.

3. Assess the quality of the literature: report and comment on heterogeneity of the studies (tau, I2), on publication bias (funnel plot), and on influential studies.

## Tips on the process to follow:

- Download the data on all published articles analyzing voice in schizophrenia and the prisma chart as reference of all articles found and reviewed
Data: https://www.dropbox.com/s/0l9ur0gaabr80a8/Matrix_MetaAnalysis_Diagnosis_updated290719.xlsx?dl=0
Prisma chart: https://www.dropbox.com/s/vbjf6ff73dv9tru/PRISMA%202009%20flow%20diagram_PP.pptx?dl=0 
- Look through the dataset to find out which columns to use, and if there is any additional information written as comments (real world data is always messy!).
    * Hint: PITCH_F0M and PITCH_F0SD group of variables are what you need
- Following the procedure in the slides calculate effect size and standard error of the effect size per each study. N.B. we focus on pitch mean (PITCH_F0_HC_M),(PITCH_F0_SZ_M) and pitch standard deviation (PITCH_F0SD_HC_M),(PITCH_F0SD_SZ_M).
 . first try using lmer (to connect to what you know of mixed effects models)
 . then use rma() (to get some juicy additional statistics)
 
- Build a forest plot of the results (forest(model))
 
- Go back to Assignment 3, add your own study to the data table, and re-run meta-analysis. Do the results change?

- Now look at the output of rma() and check tau and I2

# SETUP and LOAD-IN
```{r}
# Setup
pacman::p_load(readxl,tidyverse,tidyr, lmerTest, lme4,metafor)

# Read in excel file
df <- read_xlsx("Matrix_MetaAnalysis_Diagnosis_updated290719.xlsx")

# Counting how long the columns are without NA's
df %>% summarise(
  PitchF0HC = length(na.omit(PITCH_F0_HC_M)),
  PitchF0SZ = length(na.omit(PITCH_F0_SZ_M)),
  PitchF0SDHC = length(na.omit(PITCH_F0SD_HC_M)),
  PitchF0SDSZ = length(na.omit(PITCH_F0SD_SZ_M))
  )
```
So, we have 6 complete case-studies for Pitch-mean in healthy controls, 10 complete ones in Pitch-mean in schizophrenics, 15 complete ones in Pitch-standard-deviation-mean in healthy controls (there will be overlap with the 6) and then 20 complete ones in Pitch-standard-deviation mean in schizophrenics (again, there will be overlap here with the 10).

# GETTING STANDARDIZED MEAN DIFFERENCE (EFFECT SIZES) 
This function "escalc" creates two new columns, where yi is the observed effect size and vi is the variance which we can use in our models. SMD = standardized  mean difference, which is Cohen's d - a measure of effect size. We want it standardized because that allows us to compare across studies, and this is what we do in meta analyses. 


```{r}
# Creating effect size and sampling variance columns using escalc
WM_d <- escalc(measure = "SMD", n1i = SAMPLE_SIZE_HC, n2i = SAMPLE_SIZE_SZ, m1i = PITCH_F0_HC_M, m2i = PITCH_F0_SZ_M, sd1i = PITCH_F0_HC_SD, sd2i = PITCH_F0_SZ_SD, data = df)

# It can be seen here
test <- WM_d %>% select(StudyID,yi,vi,PITCH_F0_HC_M,PITCH_F0_SZ_M,PITCH_F0_HC_SD,PITCH_F0_SZ_SD)

```

# MODELLING BEFORE ADDING STUDIES FROM ASSIGNMENT 3
```{r}
# Making a mixed effects implementation
m <- lmer(yi ~ 1 + (1 | StudyID), weights = 1/vi, data=WM_d, control=lmerControl(check.nobs.vs.nlev="ignore", check.nobs.vs.nRE="ignore")) #Model may not have converged with 1 eigenvalue close to zero: 7.2e-10

summary(m)

# A Meta-analysis optimization:
m2 <-rma(yi, vi, data = WM_d, slab = Article) # Slab = random effect. Put here as Article to get the authors names instead of just numbers.

summary(m2)

# Making a forest and funnel plot
forest(m2)
funnel(m2)

# Checking publication bias with ranktest
ranktest(m2)

# What if we have a fixed effect?
m3 <- lmer(yi ~ 1 + TYPE_OF_TASK + (1 | StudyID), weights = 1/vi, data=WM_d, control=lmerControl(check.nobs.vs.nlev="ignore", check.nobs.vs.nRE="ignore"))

summary(m3)

```

# ADDING STUDIES FROM ASSIGNMENT 3: 
```{r}

# CODE
# ADD TO DF OR MAKE NEW (define new either way)

```

# GETTING STANDARDIZED MEAN DIFFERENCE (EFFECT SIZES) W. MORE STUDIES
```{r}
# Creating effect size and sampling variance columns using escalc
WM_d <- escalc(measure = "SMD", n1i = SAMPLE_SIZE_HC, n2i = SAMPLE_SIZE_SZ, m1i = PITCH_F0_HC_M, m2i = PITCH_F0_SZ_M, sd1i = PITCH_F0_HC_SD, sd2i = PITCH_F0_SZ_SD, data = df)

# The new effect sizes can be seen here
test <- WM_d %>% select(StudyID,yi,vi,PITCH_F0_HC_M,PITCH_F0_SZ_M,PITCH_F0_HC_SD,PITCH_F0_SZ_SD)

```


# MODELLING AFTER ADDING STUDIES FROM ASSIGNMENT 3
```{r}

# Making a mixed effects implementation
m <- lmer(yi ~ 1 + (1 | StudyID), weights = 1/vi, data=WM_d, control=lmerControl(check.nobs.vs.nlev="ignore", check.nobs.vs.nRE="ignore")) #Model may not have converged with 1 eigenvalue close to zero: 7.2e-10

summary(m)

# A Meta-analysis optimization:
m2 <-rma(yi, vi, data = WM_d, slab = Article) # Slab = random effect. Put here as Article to get the authors names instead of just numbers.

summary(m2)

# Making a forest and funnel plot
forest(m2)
funnel(m2)

# Checking publication bias with ranktest
ranktest(m2)

# What if we have a fixed effect?
m3 <- lmer(yi ~ 1 + TYPE_OF_TASK + (1 | StudyID), weights = 1/vi, data=WM_d, control=lmerControl(check.nobs.vs.nlev="ignore", check.nobs.vs.nRE="ignore"))

summary(m3)


```






